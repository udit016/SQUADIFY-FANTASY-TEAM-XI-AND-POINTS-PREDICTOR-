# main.py
"""
ENHANCED Fantasy Cricket System - XGBoost 30-Feature Variance Model
- Uses XGBoost Variance Model with 30-feature system for optimal predictions
- Creates exactly ONE valid team with NO duplicate players
- Context-based features that avoid averaging trap
- Enhanced variance prediction to break through conservative predictions
"""

import pandas as pd
import logging
from datetime import datetime, timedelta
from pathlib import Path

from src.data_loader import CricketDataLoader
from src.feature_engineer import FeatureEngineer
from src.model_training import XGBoostVarianceModel
from src.predictor import FantasyCricketPredictor
from src.optimizer import FantasyTeamOptimizer

# Setup logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


def main():
    """ENHANCED fantasy cricket pipeline with XGBoost 30-feature variance system"""
    
    print("="*90)
    print("ENHANCED XGBOOST 30-FEATURE VARIANCE FANTASY CRICKET SYSTEM")
    print("âœ“ XGBoost Variance Model - Avoids Averaging Trap")
    print("âœ“ 30-Feature Context System (Raw Values Only)")
    print("âœ“ Enhanced Player Discrimination (30 Features vs 7)")
    print("âœ“ Variance-Focused Prediction (Breaks Conservative Averaging)")
    print("âœ“ Single Valid Team (No Duplicates)")
    print("âœ“ Proper Fantasy Constraints")
    print("="*90)
    
    # =================================================================
    # CONFIGURATION
    # =================================================================
    
    squad_team1 = [446507,34102,605661,1170265,1287032,897549,625371,
297433,594322,502714,447261,1292502,1350762,277912
,1392201,30288,625383]
    squad_team2 = [
288284,326016,288284,471342,1159720,1350792,677077,542023,403902,
1161489,955235,398438,1194959,1057399,892749,253802,
1119026,823703,669365,721867
]
    venue_id = 58324
    prediction_cutoff_date = datetime(2025,4,7)
    
    models_dir = "outputs"  # XGBoost uses outputs directory
    data_dir = "data"
    
    print(f"\nCONFIGURATION:")
    print(f"- Team 1 Squad: {len(squad_team1)} players")
    print(f"- Team 2 Squad: {len(squad_team2)} players") 
    print(f"- Venue: {venue_id}")
    print(f"- Prediction Cutoff: {prediction_cutoff_date}")
    
    # =================================================================
    # STEP 1: TRAIN/LOAD XGBOOST 30-FEATURE VARIANCE MODEL
    # =================================================================
    
    print(f"\n" + "="*70)
    print("STEP 1: XGBOOST 30-FEATURE VARIANCE MODEL")
    print("="*70)
    
    model_path = Path(models_dir) / "xgboost_variance_model.pkl"
    feature_names_path = Path(models_dir) / "xgboost_feature_columns.pkl"
    
    if model_path.exists() and feature_names_path.exists():
        print("âœ“ Loading existing XGBoost 30-feature variance model...")
        
        # Load XGBoost model
        xgb_model = XGBoostVarianceModel()
        if xgb_model.load_model(str(model_path)):
            feature_count = len(xgb_model.feature_columns)
            print(f"âœ“ XGBoost variance model loaded with {feature_count} features")
            
            # Validate that we have the expected 30 features
            if feature_count == 30:
                print("âœ“ Confirmed: 30-feature XGBoost variance system loaded")
            else:
                print(f"âš  Warning: Expected 30 features, got {feature_count}")
        else:
            print("âŒ Failed to load existing model, will train new one")
            model_path = None  # Force retraining
        
    else:
        model_path = None  # Force training
    
    if model_path is None or not model_path.exists():
        print("âœ“ Training new XGBoost 30-feature variance model...")
        
        try:
            # Load data
            print("  Loading datasets...")
            data_loader = CricketDataLoader(data_dir=data_dir)
            datasets = data_loader.load_all()
            
            # Initialize feature engineer
            print("  Initializing feature engineer for 30 features...")
            feature_engineer = FeatureEngineer(max_recent_matches=3)
            
            # Create training data
            print("  Creating training dataset with 30 features...")
            training_cutoff_date = datetime(2024, 4, 1)  # Use historical data for training
            training_df = feature_engineer.create_training_dataset(
                datasets=datasets,
                training_cutoff_date=training_cutoff_date,
                sample_size=15000
            )
            
            print(f"  Training data created: {len(training_df)} samples")
            
            # Train XGBoost variance model
            print("  Training XGBoost variance model (optimized for variance prediction)...")
            xgb_model = XGBoostVarianceModel()
            results = xgb_model.train_variance_model(
                training_df=training_df,
                feature_engineer=feature_engineer,
                target_col='fantasy_points'
            )
            
            print(f"âœ“ XGBoost variance model trained successfully")
            print(f"âœ“ Training RMSE: {results['metrics']['final_rmse']:.2f}")
            print(f"âœ“ Variance Score: {results['metrics']['final_variance_score']:.3f}")
            print(f"âœ“ Prediction Std: {results['metrics']['prediction_std']:.1f}")
            print(f"âœ“ Avoiding Average Trap: {'YES' if results['metrics']['avoiding_average_trap'] else 'NO'}")
            print(f"âœ“ Feature count: {results['metrics']['feature_count']}")
            print(f"âœ“ Training samples: {results['metrics']['training_samples']}")
            
            if not results['metrics']['avoiding_average_trap']:
                print("âš  WARNING: Model may still be falling into averaging trap!")
            else:
                print("ðŸŽ‰ SUCCESS: Model successfully avoids averaging trap!")
            
            # Test model if test data available
            try:
                test_start_date = datetime(2024, 4, 1)
                test_end_date = datetime(2024, 5, 1)
                test_df = feature_engineer.create_test_dataset(
                    datasets=datasets,
                    test_start_date=test_start_date,
                    test_end_date=test_end_date
                )
                
                if len(test_df) > 0:
                    print("  Evaluating on test data...")
                    test_predictions_df = xgb_model.predict_with_variance_check(test_df, feature_engineer)
                    test_predictions = test_predictions_df['predicted_fantasy_points']
                    actual_values = test_df['fantasy_points']
                    
                    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
                    test_rmse = (mean_squared_error(actual_values, test_predictions))**0.5
                    test_mae = mean_absolute_error(actual_values, test_predictions)
                    test_r2 = r2_score(actual_values, test_predictions)
                    
                    print(f"âœ“ Test RMSE: {test_rmse:.2f}")
                    print(f"âœ“ Test MAE: {test_mae:.2f}")
                    print(f"âœ“ Test RÂ²: {test_r2:.3f}")
                    print(f"âœ“ Test Prediction Std: {test_predictions.std():.1f}")
                    
                    # Quality assessment
                    if test_r2 > 0.2:
                        print("ðŸŽ‰ EXCELLENT: XGBoost variance model showing strong predictive power!")
                    elif test_r2 > 0.1:
                        print("âœ“ GOOD: XGBoost variance model showing good predictive ability")
                    elif test_r2 > 0.05:
                        print("âš  MODERATE: XGBoost variance model showing some predictive ability")
                    else:
                        print("âŒ POOR: Model needs improvement")
                else:
                    print("âš  No test data available for evaluation")
                    
            except Exception as e:
                print(f"âš  Test evaluation failed: {e}")
            
        except Exception as e:
            logger.error(f"XGBoost model training failed: {e}")
            raise
    
    # =================================================================
    # STEP 2: LOAD DATA AND CREATE VARIANCE-FOCUSED PREDICTIONS
    # =================================================================
    
    print(f"\n" + "="*70)
    print("STEP 2: GENERATE XGBOOST 30-FEATURE VARIANCE PREDICTIONS")
    print("="*70)
    
    try:
        # Initialize predictor
        predictor = FantasyCricketPredictor(models_dir=models_dir, data_dir=data_dir)
        
        # Load model and datasets
        if not predictor.load_model():
            raise RuntimeError("Failed to load XGBoost variance model")
        
        if not predictor.load_datasets():
            raise RuntimeError("Failed to load datasets")
        
        print(f"âœ“ Predictor initialized with XGBoost 30-feature variance system")
        
        # Generate predictions
        print(f"âœ“ Creating XGBoost 30-feature variance predictions...")
        predictions_df = predictor.predict_fantasy_points(
            squad_team1=squad_team1,
            squad_team2=squad_team2,
            venue_id=venue_id,
            prediction_cutoff_date=prediction_cutoff_date
        )
        
        print(f"âœ“ XGBoost predictions generated for {len(predictions_df)} players")
        print(f"âœ“ Prediction range: {predictions_df['fp_pred'].min():.1f} to {predictions_df['fp_pred'].max():.1f}")
        print(f"âœ“ Prediction std: {predictions_df['fp_pred'].std():.1f}")
        print(f"âœ“ Average prediction: {predictions_df['fp_pred'].mean():.1f}")
        print(f"âœ“ Unique predictions: {predictions_df['fp_pred'].nunique()}/{len(predictions_df)}")
        
        # XGBoost variance model quality check
        pred_std = predictions_df['fp_pred'].std()
        variance_threshold = 10  # Same as XGBoostVarianceModel
        
        if pred_std >= variance_threshold:
            print("ðŸŽ‰ EXCELLENT: XGBoost variance model successfully avoiding averaging trap!")
            if pred_std > 20.0:
                print("ðŸ”¥ OUTSTANDING: Extremely high prediction variance achieved!")
        elif pred_std >= 5.0:
            print("âš  MODERATE: Some improvement but still approaching averaging trap")
        else:
            print("âŒ POOR: Still falling into averaging trap despite variance model")
        
        # Variance category analysis
        if 'variance_category' in predictions_df.columns:
            var_analysis = predictions_df['variance_category'].value_counts()
            print("\nVariance category distribution from XGBoost model:")
            for category, count in var_analysis.items():
                print(f"  {category}: {count} players ({count/len(predictions_df)*100:.1f}%)")
        
        # Role-based analysis
        if 'role' in predictions_df.columns:
            role_analysis = predictions_df.groupby('role')['fp_pred'].agg(['mean', 'std', 'count'])
            print("\nRole-based prediction analysis from XGBoost features:")
            for role, stats in role_analysis.iterrows():
                print(f"  {role}: avg={stats['mean']:.1f}, std={stats['std']:.1f}, count={stats['count']}")
        
        # Display top predictions
        predictor.print_predictions(predictions_df, show_top=15)
        
        # Get prediction distribution analysis
        distribution_analysis = predictor.get_prediction_distribution_analysis(predictions_df)
        if distribution_analysis:
            print(f"\nXGBoost Prediction Distribution Analysis:")
            print(f"- Coefficient of Variation: {distribution_analysis.get('variance_quality', {}).get('coefficient_of_variation', 0):.3f}")
            print(f"- High Scores (â‰¥50): {distribution_analysis.get('distribution', {}).get('high_scores', 0)}")
            print(f"- Very High Scores (â‰¥70): {distribution_analysis.get('distribution', {}).get('very_high_scores', 0)}")
        
    except Exception as e:
        logger.error(f"XGBoost prediction generation failed: {e}")
        raise
    
    # =================================================================
    # STEP 3: OPTIMIZE SINGLE TEAM WITH XGBOOST VARIANCE PREDICTIONS
    # =================================================================
    
    print(f"\n" + "="*70)
    print("STEP 3: OPTIMIZE TEAM WITH XGBOOST 30-FEATURE VARIANCE PREDICTIONS")
    print("="*70)
    
    try:
        optimizer = FantasyTeamOptimizer(max_per_team=7)
        
        print("âœ“ Creating optimal team using XGBoost variance predictions...")
        prediction_date = prediction_cutoff_date
        
        # Load player innings data for starting probability calculation
        data_loader = CricketDataLoader(data_dir=data_dir)
        datasets = data_loader.load_all()
        player_innings_data = datasets['player_innings']

        team_df, captain_id, vice_captain_id = optimizer.optimize_single_team(
            predictions_df, 
            match_date=prediction_date,
            player_innings_df=player_innings_data
        )
        
        print(f"âœ“ XGBoost variance team optimization successful!")
        print(f"âœ“ Team size: {len(team_df)} players")
        print(f"âœ“ Total predicted points: {team_df['fp_pred'].sum():.1f}")
        print(f"âœ“ Team prediction std: {team_df['fp_pred'].std():.1f}")
        print(f"âœ“ Captain: Player {captain_id}")
        print(f"âœ“ Vice-Captain: Player {vice_captain_id}")
        
        # Variance analysis for selected team
        team_variance_quality = "HIGH" if team_df['fp_pred'].std() > 8 else "MODERATE" if team_df['fp_pred'].std() > 4 else "LOW"
        print(f"âœ“ Team variance quality: {team_variance_quality}")
        
    except Exception as e:
        logger.error(f"Team optimization failed: {e}")
        raise
    
    # =================================================================
    # OUTPUT: DISPLAY RESULTS
    # =================================================================
    
    print(f"\n" + "="*90)
    print("TOP 15 PLAYERS BY XGBOOST 30-FEATURE VARIANCE PREDICTIONS")
    print("="*90)
    
    top_15 = predictions_df.head(15)
    print(f"{'Rank':<4} | {'Player ID':<10} | {'Name':<20} | {'Team':<6} | {'Role':<12} | {'Points':<8} | {'Var Cat':<12}")
    print("-" * 88)
    
    for idx, (_, player) in enumerate(top_15.iterrows(), 1):
        player_id = player['player_id']
        name = str(player.get('name', f'Player_{player_id}'))[:20]
        var_category = str(player.get('variance_category', 'Unknown'))[:12]
        print(f"{idx:<4} | {player_id:<10} | {name:<20} | T{player['team_id']:<5} | {str(player.get('role', 'Unknown'))[:12]:<12} | {player['fp_pred']:<8.1f} | {var_category:<12}")
    
    print(f"\n" + "="*90)
    print("OPTIMIZED FANTASY TEAM (XGBOOST 30-FEATURE VARIANCE SYSTEM)")
    print("="*90)
    
    # Display team
    optimizer.print_team_details(team_df, captain_id, vice_captain_id)
    
    # =================================================================
    # SAVE RESULTS
    # =================================================================
    
    print(f"\n" + "="*70)
    print("SAVING XGBOOST VARIANCE RESULTS")
    print("="*70)
    
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    
    try:
        # Save all predictions
        predictions_file = f"xgboost_30_feature_variance_predictions_{timestamp}.csv"
        predictions_df.to_csv(predictions_file, index=False)
        print(f"âœ“ XGBoost variance predictions saved: {predictions_file}")
        
        # Save optimal team
        team_file = f"xgboost_variance_optimal_team_{timestamp}.csv"
        team_df_save = team_df.copy()
        team_df_save['captain'] = team_df_save['player_id'] == captain_id
        team_df_save['vice_captain'] = team_df_save['player_id'] == vice_captain_id
        team_df_save.to_csv(team_file, index=False)
        print(f"âœ“ XGBoost variance optimal team saved: {team_file}")
        
        # Save prediction summary
        predictor.save_predictions(predictions_df, f"xgboost_variance_predictions_with_analysis_{timestamp}.csv")
        
    except Exception as e:
        logger.warning(f"Error saving files: {e}")
    
    # =================================================================
    # ADVANCED ANALYSIS
    # =================================================================
    
    print(f"\n" + "="*70)
    print("ADVANCED XGBOOST VARIANCE ANALYSIS")
    print("="*70)
    
    try:
        # Get feature importance
        feature_importance = predictor.get_feature_importance()
        if feature_importance is not None and len(feature_importance) > 0:
            print("Top 15 Most Important Features:")
            for idx, (_, feature) in enumerate(feature_importance.head(15).iterrows(), 1):
                print(f"  {idx:2d}. {feature['feature']:35s}: {feature['importance']:.4f}")
        else:
            print("âš  Feature importance not available")
        
        # Prediction analysis
        analysis = predictor.analyze_predictions(predictions_df)
        print(f"\nXGBoost Variance Model Quality Metrics:")
        print(f"- Model Type: {analysis.get('model_type', 'XGBoost Variance')}")
        print(f"- Prediction Variety: {analysis.get('prediction_variety', 0)*100:.1f}%")
        print(f"- Range Quality: {analysis.get('range_quality', 'Unknown')}")
        print(f"- Variance Quality: {analysis.get('variance_quality', 'Unknown')}")
        print(f"- Avoiding Average Trap: {'YES' if analysis.get('variance_maintained', False) else 'NO'}")
        
        # XGBoost specific metrics
        xgb_metrics = analysis.get('xgboost_metrics', {})
        if xgb_metrics:
            print(f"- Diversity Score: {xgb_metrics.get('prediction_diversity_score', 0):.3f}")
            print(f"- Variance Score: {xgb_metrics.get('variance_score', 0):.3f}/1.0")
        
    except Exception as e:
        logger.warning(f"Advanced analysis failed: {e}")
    
    # =================================================================
    # FINAL SUMMARY
    # =================================================================
    
    print(f"\n" + "="*90)
    print("XGBOOST 30-FEATURE VARIANCE FANTASY CRICKET SYSTEM - COMPLETE")
    print("="*90)
    
    predictions = predictions_df['fp_pred'].values
    
    print(f"\nXGBOOST VARIANCE SYSTEM IMPROVEMENTS:")
    print(f"âœ“ Variance-Focused Model: Specifically designed to avoid averaging trap")
    print(f"âœ“ Feature Count: 30 context-based features (vs 7 basic)")
    print(f"âœ“ Raw Context Features: No averaging/trending - pure contextual data")
    print(f"âœ“ Prediction Range: {predictions.min():.1f} to {predictions.max():.1f} points")
    print(f"âœ“ Prediction Variance: {predictions.std():.1f} standard deviation")
    variance_status = "EXCELLENT" if predictions.std() >= 10 else "MODERATE" if predictions.std() >= 5 else "POOR"
    print(f"âœ“ Variance Status: {variance_status} (threshold: 10.0)")
    print(f"âœ“ No Duplicate Players: {len(team_df)} unique players")
    print(f"âœ“ Valid Team Structure: All constraints satisfied")
    print(f"âœ“ Advanced Captain Selection: Based on prediction Ã— starting probability")
    
    if 'starting_probability' in team_df.columns:
        print(f"âœ“ Starting Probability Analysis: {team_df['starting_probability'].mean():.1%} avg confidence")
    
    print(f"\nOPTIMIZED TEAM STATISTICS:")
    print(f"- Total Predicted Points: {team_df['fp_pred'].sum():.1f}")
    
    if 'starting_probability' in team_df.columns:
        weighted_points = (team_df['fp_pred'] * team_df['starting_probability']).sum()
        print(f"- Weighted Predicted Points: {weighted_points:.1f}")
    
    print(f"- Credits Used: {team_df['credits'].sum():.1f}/100.0")
    
    captain_row = team_df[team_df['player_id'] == captain_id].iloc[0]
    vice_captain_row = team_df[team_df['player_id'] == vice_captain_id].iloc[0]
    
    captain_prob = captain_row.get('starting_probability', 1.0)
    vice_captain_prob = vice_captain_row.get('starting_probability', 1.0)
    
    print(f"- Captain: Player {captain_id} ({captain_row['fp_pred']:.1f} points, {captain_prob:.1%} start chance)")
    print(f"- Vice-Captain: Player {vice_captain_id} ({vice_captain_row['fp_pred']:.1f} points, {vice_captain_prob:.1%} start chance)")
    
    if 'role' in team_df.columns:
        role_dist = team_df['role'].value_counts().to_dict()
        print(f"- Role Distribution: {role_dist}")
    
    team_dist = team_df['team_id'].value_counts().to_dict()
    print(f"- Team Distribution: {team_dist}")
    
    if 'starting_probability' in team_df.columns:
        high_prob_starters = (team_df['starting_probability'] >= 0.8).sum()
        print(f"- High Confidence Starters (â‰¥80%): {high_prob_starters}/11")
    
    # 30-feature system breakdown
    print(f"\nXGBOOST 30-FEATURE BREAKDOWN:")
    print(f"- Recent Performance (1-10): Raw runs, wickets, outs from last 3 matches")
    print(f"- Player Archetype (11-15): Current year max/min scores, performance counts")  
    print(f"- Ball-by-Ball Context (16-20): Powerplay boundaries, death runs, dots")
    print(f"- Opposition Context (21-24): Opponent bowling stats, form, strategy")
    print(f"- Venue Context (25-28): Venue scoring patterns, boundaries, difficulty")
    print(f"- Match Context (29-30): High-scoring venue flag, player experience at venue")
    
    # Quality assessment
    avg_trap_avoided = predictions.std() >= 10
    pred_quality = "EXCELLENT" if avg_trap_avoided and predictions.std() > 15 else "GOOD" if avg_trap_avoided else "MODERATE" if predictions.std() > 5 else "POOR"
    print(f"\nSYSTEM QUALITY: {pred_quality}")
    print(f"- Prediction Discrimination: {predictions_df['fp_pred'].nunique()}/{len(predictions_df)} unique predictions ({predictions_df['fp_pred'].nunique()/len(predictions_df)*100:.1f}%)")
    print(f"- Averaging Trap Status: {'AVOIDED' if avg_trap_avoided else 'NOT AVOIDED'}")
    print(f"- Variance Model Success: {'YES' if avg_trap_avoided else 'NEEDS IMPROVEMENT'}")
    print(f"- Context Feature Utilization: Full 30-feature raw context system")
    print(f"- Temporal Data Strategy: Last 3 matches for stability")
    
    # Model performance summary
    if 'xgboost_model' in locals():
        training_metrics = xgb_model.training_metrics if hasattr(xgb_model, 'training_metrics') else {}
        if training_metrics:
            print(f"\nMODEL PERFORMANCE SUMMARY:")
            print(f"- Training RMSE: {training_metrics.get('final_rmse', 0):.2f}")
            print(f"- Variance Score: {training_metrics.get('final_variance_score', 0):.3f}")
            print(f"- Best Iteration: {training_metrics.get('best_iteration', 'Unknown')}")
            print(f"- Training Samples: {training_metrics.get('training_samples', 0):,}")
    
    print("="*90)
    
    return {
        'predictions': predictions_df,
        'team': team_df,
        'captain_id': captain_id,
        'vice_captain_id': vice_captain_id,
        'prediction_range': (predictions.min(), predictions.max()),
        'prediction_std': predictions.std(),
        'team_total': team_df['fp_pred'].sum(),
        'feature_count': 30,
        'system_type': 'XGBoost 30-Feature Variance System',
        'variance_maintained': predictions.std() >= 10,
        'averaging_trap_avoided': predictions.std() >= 10,
        'model_type': 'XGBoost Variance Model'
    }


if __name__ == "__main__":
    results = main()